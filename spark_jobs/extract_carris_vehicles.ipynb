{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PedroTechy/CarrisInsight/blob/streaming_development/spark_jobs/extract_carris_vehicles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TputMQpEi4ax"
      },
      "source": [
        "# Step 1: Authenticate with Google Cloud\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoSKBOhCi4a3",
        "outputId": "7bcd2088-0952-4f38-ecea-834d0aaa4a67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your browser has been opened to visit:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=J6N3ibxNqLovcG4msfcTEHEetXC11r&access_type=offline&code_challenge=ycYyvB3j8Kzo6bTw0QilWjlp2t0cd9QkW3mQQutWDqE&code_challenge_method=S256\n",
            "\n",
            "\n",
            "Credentials saved to file: [/Users/ineslopes/.config/gcloud/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\u001b[1;33mWARNING:\u001b[0m \n",
            "Cannot add the project \"data-eng-dev-437916\" to ADC as the quota project because the account in ADC does not have the \"serviceusage.services.use\" permission on this project. You might receive a \"quota_exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n"
          ]
        }
      ],
      "source": [
        "!gcloud auth application-default login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5joskWjSi4a5"
      },
      "source": [
        "# Step 2: Install Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnykj576wq14",
        "outputId": "2363d0a5-f56e-4daf-e910-a089f48459e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /Users/ineslopes/Documents/de_edit/CarrisInsight/.project/lib/python3.13/site-packages (3.5.4)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /Users/ineslopes/Documents/de_edit/CarrisInsight/.project/lib/python3.13/site-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4IR_oNvi4a9"
      },
      "source": [
        "# Step 3: Setup Spark Env and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E8AB-EuOxXAD"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, LongType\n",
        "from pyspark.sql.functions import min, max, first, last, col, window, from_unixtime, to_timestamp, count, udf\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Kd0js4ULxYOE"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/01/21 18:57:24 WARN Utils: Your hostname, Iness-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.9 instead (on interface en0)\n",
            "25/01/21 18:57:24 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "25/01/21 18:57:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "25/01/21 18:57:32 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
            "25/01/21 18:57:32 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
          ]
        }
      ],
      "source": [
        "home_directory = os.getenv(\"HOME\")\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName('pyspark-run-with-gcp-bucket') \\\n",
        "    .config(\"spark.jars\", \"https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-hadoop3-latest.jar\") \\\n",
        "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \\\n",
        "    .getOrCreate()\n",
        "\n",
        "gs_input_path = \"gs://edit-de-project-streaming-data/carris-vehicles\"\n",
        "spark._jsc.hadoopConfiguration().set(\"google.cloud.auth.service.account.json.keyfile\",\n",
        "                                     f\"{home_directory}/.config/gcloud/application_default_credentials.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BJKtwKfCi4bB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OUX7Hw_TW02b"
      },
      "outputs": [],
      "source": [
        "#Cleaning the path to ensure clean directories\n",
        "!rm -rf content/lake/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoLfFeUObaY2"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiGVmPmKbaVt"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo74DP8Fi4bB"
      },
      "source": [
        "# Step 4: Define Schema and User Defined Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "ei6YYuAei4bB"
      },
      "outputs": [],
      "source": [
        "# Define the schema for your JSON files\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"bearing\", FloatType(), True),\n",
        "    StructField(\"block_id\", StringType(), True),\n",
        "    StructField(\"current_status\", StringType(), True),\n",
        "    StructField(\"id\", StringType(), True),\n",
        "    StructField(\"lat\", FloatType(), True),\n",
        "    StructField(\"line_id\", StringType(), True),\n",
        "    StructField(\"lon\", FloatType(), True),\n",
        "    StructField(\"pattern_id\", StringType(), True),\n",
        "    StructField(\"route_id\", StringType(), True),\n",
        "    StructField(\"schedule_relationship\", StringType(), True),\n",
        "    StructField(\"shift_id\", StringType(), True),\n",
        "    StructField(\"speed\", FloatType(), True),\n",
        "    StructField(\"stop_id\", StringType(), True),\n",
        "    StructField(\"timestamp\", LongType(), True),\n",
        "    StructField(\"trip_id\", StringType(), True)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "ZBlciteo7N2G"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "sKkRDGxVIukk"
      },
      "outputs": [],
      "source": [
        "def get_stops(spark):\n",
        "    url = f\"https://api.carrismetropolitana.pt/stops\"\n",
        "    response = requests.get(url)\n",
        "\n",
        "    filtered = [{'stop_id': stop['stop_id'], 'stop_lat': float(\n",
        "        stop['lat']), 'stop_lon': float(stop['lon'])} for stop in json.loads(response.text)]\n",
        "    \n",
        "    schema = StructType([\n",
        "    StructField(\"stop_id\", StringType(), True),\n",
        "    StructField(\"stop_lat\", FloatType(), True),\n",
        "    StructField(\"stop_lon\", FloatType(), True)])\n",
        "\n",
        "    stops = spark.createDataFrame(filtered, schema=schema)\n",
        "\n",
        "    return stops\n",
        "stops = get_stops(spark)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "def aggregate_data(df):\n",
        "    window_spec = window(\"timestamp\", \"2 minutes\", \"10 seconds\")\n",
        "\n",
        "    transformed = (df.withWatermark(\"timestamp\", \"3 minutes\")\n",
        "    .groupBy(\"id\", \"trip_id\", window_spec)\n",
        "    .agg(\n",
        "        max(\"current_status\").alias(\"current_status\"),\n",
        "        max(\"route_id\").alias(\"route_id\"),\n",
        "        max(\"stop_id\").alias(\"stop_id\"),\n",
        "        min(\"timestamp\").alias(\"first_timestamp\"),\n",
        "        max(\"timestamp\").alias(\"last_timestamp\"),\n",
        "        first(\"lat\").alias(\"first_lat\"),\n",
        "        first(\"lon\").alias(\"first_lon\"),\n",
        "        last(\"lat\").alias(\"last_lat\"),\n",
        "        last(\"lon\").alias(\"last_lon\")\n",
        "    )\n",
        "    )\n",
        "    return transformed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.radi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_distances_without_udf(df):\n",
        "    print(\"started transform\")\n",
        "    dist_df = (df\n",
        "               .withColumn(\n",
        "                   \"distance_km\",\n",
        "                   6371.0 * (2 * math.atan2(\n",
        "                       math.sqrt(\n",
        "\n",
        "                           np.sin(\n",
        "                               (np.radians(col(\"latitude_2\")) - np.radians(col(\"latitude_1\"))) / 2)**2 +\n",
        "\n",
        "                           np.cos(np.radians(col(\"latitude_1\"))) * np.cos(np.radians(col(\"latitude_2\"))) *\n",
        "                           np.sin((np.radians(col(\"longitude_2\")) -\n",
        "                                     np.radians(col(\"longitude_1\")))/2)**2\n",
        "\n",
        "                       ),\n",
        "                       math.sqrt(1 - (np.sin(\n",
        "                           (np.radians(col(\"latitude_2\")) - np.radians(col(\"latitude_1\"))) / 2)**2 +\n",
        "\n",
        "                           np.cos(np.radians(col(\"latitude_1\"))) * np.cos(np.radians(col(\"latitude_2\"))) *\n",
        "                           np.sin((np.radians(col(\"longitude_2\")) - np.radians(col(\"longitude_1\")))/2)**2))))\n",
        "               )\n",
        "               .withColumn(\n",
        "                   \"time_delta\", col(\"last_timestamp\").cast(\"long\") -\n",
        "                   col(\"first_timestamp\").cast(\"long\")\n",
        "               ).withColumn(\"average_speed\", col(\"distance\") / (col(\"time_delta\") / 3600))\n",
        "               )\n",
        "    print(\"ended transform\")\n",
        "\n",
        "    return dist_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_distances(df):\n",
        "    print(\"started transform\")\n",
        "    dist_df = (df.withColumn(\n",
        "        \"distance\",\n",
        "        haversine_udf(col(\"first_lat\"), col(\"first_lon\"), col(\"last_lat\"), col(\"last_lon\")\n",
        "        ))\n",
        "    .withColumn(\n",
        "        \"time_delta\", col(\"last_timestamp\").cast(\"long\") - col(\"first_timestamp\").cast(\"long\")\n",
        "    ).withColumn(\"average_speed\", col(\"distance\") / (col(\"time_delta\") / 3600))\n",
        "        )\n",
        "    print(\"ended transform\")\n",
        "\n",
        "    return dist_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DtGnQQ5JwOT"
      },
      "source": [
        "## Step 5: Start streaming and transformation process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ixu4EnWx3HwY",
        "outputId": "f9aff7a2-68a0-4b58-f000-dec0c75138c6"
      },
      "outputs": [],
      "source": [
        "df = (spark.readStream.option(\"maxFilesPerTrigger\", 1)\n",
        "    .format(\"json\")\n",
        "    .schema(schema)\n",
        "    .load(gs_input_path))\n",
        "print(\"will start streaming\")\n",
        "\n",
        "\n",
        "transformed_df = df.withColumn(\"timestamp\", to_timestamp(from_unixtime(\"timestamp\")))\n",
        "# Write a df with the datetype transform only\n",
        "print(\"Transformed data\")\n",
        "\n",
        "\n",
        "# Group by vehicle ID and window, then get the first and last timestamps and lat/lon values\n",
        "result_df = (\n",
        "    transformed_df.transform(aggregate_data).transform(calculate_distances)\n",
        "\n",
        ")\n",
        "\n",
        "query = (result_df.writeStream\n",
        ".outputMode('append')\n",
        ".option('checkpointLocation', 'content/lake/processing/vehicles_checkpoint')\n",
        ".trigger(processingTime='10 seconds')\n",
        ".start('content/lake/processing/vehicles/data')\n",
        ")\n",
        "\n",
        "query.awaitTermination(30)\n",
        "\n",
        "query.stop()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irMdRfeGJ53f"
      },
      "source": [
        "## Step 6: Read and verify results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SU7P7Bs26c4C"
      },
      "outputs": [],
      "source": [
        "df = spark.read.format(\"parquet\").load(\"content/lake/processing/vehicles/data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55izQz3EI_Va",
        "outputId": "862564bb-3833-4834-d02f-d9242773e98e"
      },
      "outputs": [],
      "source": [
        "view = (df\n",
        " .orderBy(\"last_timestamp\", ascending=False)\n",
        " .dropDuplicates([\"id\"])\n",
        " .join(stops, how='left', on='stop_id')\n",
        " .withColumn(\"distance_till_stop\", haversine_udf(col(\"last_lat\"), col('last_lon'), col('stop_lat'), col('stop_lon')))\n",
        " .withColumn(\"stop_eta\", col(\"distance_till_stop\") / col(\"average_speed\") *60)\n",
        " )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHMQYUvxGmIn",
        "outputId": "c67b2019-6df4-489f-b28b-7384acea93f9"
      },
      "outputs": [],
      "source": [
        "view.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
