{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from send_to_query import *\n",
    "BUCKET_NAME = 'edit-data-eng-project-group3'  # Replace with your bucket name\n",
    "SOURCE_JSON_FILE = 'lines.json'  # Path to the JSON file in the bucket\n",
    "BIGQUERY_PROJECT = 'data-eng-dev-437916'  # Replace with your project ID\n",
    "BIGQUERY_DATASET = 'data_eng_project_group3'  # Replace with your BigQuery dataset name\n",
    "BIGQUERY_TABLE = 'lines_test'  # Replace with your BigQuery table name\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ineslopes/Documents/de_edit/CarrisInsight/.project/lib/python3.13/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/Users/ineslopes/Documents/de_edit/CarrisInsight/.project/lib/python3.13/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     color facilities    id                                localities  \\\n",
      "0  #C61D23         []  1001   [Alfragide, Amadora, Reboleira, Buraca]   \n",
      "1  #C61D23         []  1002  [Reboleira, Amadora, Atalaia, Alfragide]   \n",
      "2  #C61D23         []  1003                   [Amadora Este, Amadora]   \n",
      "3  #C61D23         []  1004           [Amadora, Moinhos da Funcheira]   \n",
      "4  #C61D23         []  1005                  [Amadora, Casal da Mira]   \n",
      "\n",
      "                                           long_name municipalities  \\\n",
      "0   Alfragide (Estr Seminario) - Reboleira (Estação)         [1115]   \n",
      "1  Reboleira (Estação) | Circular via Alfragide (...         [1115]   \n",
      "2     Amadora (Estação Norte) - Amadora Este (Metro)         [1115]   \n",
      "3  Amadora (Estação Norte) via Moinhos da Funchei...         [1115]   \n",
      "4                     Amadora (Estação Norte) - UBBO         [1115]   \n",
      "\n",
      "                                   patterns                    routes  \\\n",
      "0                      [1001_0_1, 1001_0_2]                  [1001_0]   \n",
      "1                                [1002_0_3]                  [1002_0]   \n",
      "2                      [1003_0_2, 1003_0_1]                  [1003_0]   \n",
      "3                                [1004_0_3]                  [1004_0]   \n",
      "4  [1005_0_1, 1005_0_2, 1005_1_2, 1005_2_3]  [1005_0, 1005_1, 1005_2]   \n",
      "\n",
      "  short_name text_color  \n",
      "0       1001    #FFFFFF  \n",
      "1       1002    #FFFFFF  \n",
      "2       1003    #FFFFFF  \n",
      "3       1004    #FFFFFF  \n",
      "4       1005    #FFFFFF  \n"
     ]
    }
   ],
   "source": [
    "dataframe = read_json_from_gcs(BUCKET_NAME, SOURCE_JSON_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_none_list(col):\n",
    "    if type(col[0]) == list:\n",
    "        return  col.apply( lambda row: [item for item in row if item != None])\n",
    "    else: \n",
    "        return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will apply the funtion to all columns\n",
    "data = dataframe.apply(clean_none_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = pd.read_csv('lines_csv.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 721 entries, 0 to 720\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Unnamed: 0      721 non-null    int64 \n",
      " 1   color           721 non-null    object\n",
      " 2   facilities      721 non-null    object\n",
      " 3   id              721 non-null    object\n",
      " 4   localities      721 non-null    object\n",
      " 5   long_name       721 non-null    object\n",
      " 6   municipalities  721 non-null    object\n",
      " 7   patterns        721 non-null    object\n",
      " 8   routes          721 non-null    object\n",
      " 9   short_name      721 non-null    object\n",
      " 10  text_color      721 non-null    object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 62.1+ KB\n"
     ]
    }
   ],
   "source": [
    "clean.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 721 entries, 0 to 720\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   color           721 non-null    object\n",
      " 1   facilities      721 non-null    object\n",
      " 2   id              721 non-null    object\n",
      " 3   localities      721 non-null    object\n",
      " 4   long_name       721 non-null    object\n",
      " 5   municipalities  721 non-null    object\n",
      " 6   patterns        721 non-null    object\n",
      " 7   routes          721 non-null    object\n",
      " 8   short_name      721 non-null    object\n",
      " 9   text_color      721 non-null    object\n",
      "dtypes: object(10)\n",
      "memory usage: 56.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ineslopes/Documents/de_edit/CarrisInsight/.project/lib/python3.13/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "Error converting Pandas column with name: \"facilities\" and datatype: \"object\" to an appropriate pyarrow datatype: Array, ListArray, or StructArray\n"
     ]
    },
    {
     "ename": "ArrowTypeError",
     "evalue": "Error converting Pandas column with name: \"facilities\" and datatype: \"object\" to an appropriate pyarrow datatype: Array, ListArray, or StructArray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/de_edit/CarrisInsight/.project/lib/python3.13/site-packages/google/cloud/bigquery/_pandas_helpers.py:343\u001b[0m, in \u001b[0;36mbq_to_arrow_array\u001b[0;34m(series, bq_field)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pyarrow\u001b[38;5;241m.\u001b[39mStructArray\u001b[38;5;241m.\u001b[39mfrom_pandas(series, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39marrow_type)\n\u001b[0;32m--> 343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpyarrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mArray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrow_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pyarrow\u001b[38;5;241m.\u001b[39mArrowTypeError:\n",
      "File \u001b[0;32m~/Documents/de_edit/CarrisInsight/.project/lib/python3.13/site-packages/pyarrow/array.pxi:1126\u001b[0m, in \u001b[0;36mpyarrow.lib.Array.from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/de_edit/CarrisInsight/.project/lib/python3.13/site-packages/pyarrow/array.pxi:360\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/de_edit/CarrisInsight/.project/lib/python3.13/site-packages/pyarrow/array.pxi:87\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/de_edit/CarrisInsight/.project/lib/python3.13/site-packages/pyarrow/error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: Expected bytes, got a 'list' object",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mload_to_bigquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBIGQUERY_PROJECT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBIGQUERY_DATASET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBIGQUERY_TABLE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/de_edit/CarrisInsight/airflow_dags/send_to_query.py:47\u001b[0m, in \u001b[0;36mload_to_bigquery\u001b[0;34m(dataframe, project, dataset, table)\u001b[0m\n\u001b[1;32m     43\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead json from bucket and converted to csv.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_to_bigquery\u001b[39m(dataframe, project, dataset, table):\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# Upload dataframe \u001b[39;00m\n\u001b[1;32m     50\u001b[0m     client \u001b[38;5;241m=\u001b[39m bigquery\u001b[38;5;241m.\u001b[39mClient(project\u001b[38;5;241m=\u001b[39mproject)\n\u001b[1;32m     51\u001b[0m     table_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/de_edit/CarrisInsight/.project/lib/python3.13/site-packages/google/cloud/bigquery/client.py:2806\u001b[0m, in \u001b[0;36mClient.load_table_from_dataframe\u001b[0;34m(self, dataframe, destination, num_retries, job_id, job_id_prefix, location, project, job_config, parquet_compression, timeout)\u001b[0m\n\u001b[1;32m   2803\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parquet_compression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnappy\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# adjust the default value\u001b[39;00m\n\u001b[1;32m   2804\u001b[0m         parquet_compression \u001b[38;5;241m=\u001b[39m parquet_compression\u001b[38;5;241m.\u001b[39mupper()\n\u001b[0;32m-> 2806\u001b[0m     \u001b[43m_pandas_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataframe_to_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2807\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2808\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_job_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2809\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtmppath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparquet_compression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparquet_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2811\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparquet_use_compliant_nested_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2812\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2814\u001b[0m     dataframe\u001b[38;5;241m.\u001b[39mto_parquet(\n\u001b[1;32m   2815\u001b[0m         tmppath,\n\u001b[1;32m   2816\u001b[0m         engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2822\u001b[0m         ),\n\u001b[1;32m   2823\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/de_edit/CarrisInsight/.project/lib/python3.13/site-packages/google/cloud/bigquery/_pandas_helpers.py:689\u001b[0m, in \u001b[0;36mdataframe_to_parquet\u001b[0;34m(dataframe, bq_schema, filepath, parquet_compression, parquet_use_compliant_nested_type)\u001b[0m\n\u001b[1;32m    682\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    683\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_compliant_nested_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: parquet_use_compliant_nested_type}\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _versions_helpers\u001b[38;5;241m.\u001b[39mPYARROW_VERSIONS\u001b[38;5;241m.\u001b[39muse_compliant_nested_type\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    686\u001b[0m )\n\u001b[1;32m    688\u001b[0m bq_schema \u001b[38;5;241m=\u001b[39m schema\u001b[38;5;241m.\u001b[39m_to_schema_fields(bq_schema)\n\u001b[0;32m--> 689\u001b[0m arrow_table \u001b[38;5;241m=\u001b[39m \u001b[43mdataframe_to_arrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbq_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m pyarrow\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mwrite_table(\n\u001b[1;32m    691\u001b[0m     arrow_table,\n\u001b[1;32m    692\u001b[0m     filepath,\n\u001b[1;32m    693\u001b[0m     compression\u001b[38;5;241m=\u001b[39mparquet_compression,\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    695\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/de_edit/CarrisInsight/.project/lib/python3.13/site-packages/google/cloud/bigquery/_pandas_helpers.py:632\u001b[0m, in \u001b[0;36mdataframe_to_arrow\u001b[0;34m(dataframe, bq_schema)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bq_field \u001b[38;5;129;01min\u001b[39;00m bq_schema:\n\u001b[1;32m    630\u001b[0m     arrow_names\u001b[38;5;241m.\u001b[39mappend(bq_field\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    631\u001b[0m     arrow_arrays\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 632\u001b[0m         \u001b[43mbq_to_arrow_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_column_or_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbq_field\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbq_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m     )\n\u001b[1;32m    634\u001b[0m     arrow_fields\u001b[38;5;241m.\u001b[39mappend(bq_to_arrow_field(bq_field, arrow_arrays[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtype))\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m((field \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m arrow_fields)):\n",
      "File \u001b[0;32m~/Documents/de_edit/CarrisInsight/.project/lib/python3.13/site-packages/google/cloud/bigquery/_pandas_helpers.py:347\u001b[0m, in \u001b[0;36mbq_to_arrow_array\u001b[0;34m(series, bq_field)\u001b[0m\n\u001b[1;32m    345\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mError converting Pandas column with name: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseries\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and datatype: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseries\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to an appropriate pyarrow datatype: Array, ListArray, or StructArray\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    346\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39merror(msg)\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m pyarrow\u001b[38;5;241m.\u001b[39mArrowTypeError(msg)\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: Error converting Pandas column with name: \"facilities\" and datatype: \"object\" to an appropriate pyarrow datatype: Array, ListArray, or StructArray"
     ]
    }
   ],
   "source": [
    "load_to_bigquery(data, BIGQUERY_PROJECT, BIGQUERY_DATASET, BIGQUERY_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 721 entries, 0 to 720\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   color           721 non-null    object\n",
      " 1   facilities      721 non-null    object\n",
      " 2   id              721 non-null    object\n",
      " 3   localities      721 non-null    object\n",
      " 4   long_name       721 non-null    object\n",
      " 5   municipalities  721 non-null    object\n",
      " 6   patterns        721 non-null    object\n",
      " 7   routes          721 non-null    object\n",
      " 8   short_name      721 non-null    object\n",
      " 9   text_color      721 non-null    object\n",
      "dtypes: object(10)\n",
      "memory usage: 56.5+ KB\n"
     ]
    }
   ],
   "source": [
    "with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
    "    # Step 3: List the files in the zip\n",
    "    zip_file_list = zip_ref.namelist()\n",
    "    print(f\"Files in the zip archive: {zip_file_list}\")\n",
    "\n",
    "    # Step 4: Extract and parse the specific file you want\n",
    "    target_filename = \"yourfile.txt\"  # Replace with the actual file you're interested in\n",
    "\n",
    "    if target_filename in zip_file_list:\n",
    "        with zip_ref.open(target_filename) as target_file:\n",
    "            # Example: Read the file and parse its content\n",
    "            file_content = target_file.read().decode('utf-8')  # Decode the bytes to string if it's a text file\n",
    "            print(f\"Content of {target_filename}:\\n\")\n",
    "            print(file_content)\n",
    "    else:\n",
    "        print(f\"{target_filename} not found in the zip archive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../stop_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped = df.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped.to_csv('chunk.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
